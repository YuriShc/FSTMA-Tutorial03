{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704fb8be-c0a2-4272-ab39-1933a8eac78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import random\n",
    "import gym\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "from AI_agents.Environments.gym_problem import GymProblem\n",
    "from AI_agents.Search.best_first_search import a_star\n",
    "\n",
    "from IL.dataset import ImitationLearningDataset\n",
    "from IL.evaluation import evaluate_policy\n",
    "from IL.ipython_vis import animate_policy\n",
    "from IL.model import MLP\n",
    "from IL.training import train_torch_classifier_sgd\n",
    "import AI_agents.Search.utils as utils\n",
    "\n",
    "\n",
    "# initialize env\n",
    "env = gym.make(\"Taxi-v3\").env\n",
    "env.reset()\n",
    "\n",
    "PASSENGER_IN_TAXI = 4  # passenger idx when in taxi\n",
    "locs = env.unwrapped.locs  # environment locations\n",
    "\n",
    "# random seed\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc5dc85-ed30-43c4-986d-58f4fbbbd8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaxiMonteCarloPolicy:\n",
    "    def __init__(self):\n",
    "        # a container for the plan actions.\n",
    "        self.cur_plan = deque()\n",
    "    \n",
    "    def __call__(self, obs):\n",
    "        # if out of actions (finished previous plan), or if observation is not in current plan,\n",
    "        # create a new plan.\n",
    "        taxi_prob = GymProblem(env, env.unwrapped.s)\n",
    "        actions = list(taxi_prob.get_applicable_actions(utils.Node(utils.State(obs, False), None, None, 0)))\n",
    "        chosen_action = random.choice(actions)\n",
    "        return chosen_action\n",
    "    \n",
    "helicopter_policy = TaxiMonteCarloPolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "081d228b-7f05-405a-a426-8dc89f9e60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will run forever until it is interrupted\n",
    "#animate_policy(env, helicopter_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd66e6d1-c780-44b2-9aac-35b7968596c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trajectory struct\n",
    "class Trajectory:\n",
    "    def __init__(self, observations=None, actions=None, rewards=None):\n",
    "        self.observations = observations or []\n",
    "        self.actions = actions or []\n",
    "        self.rewards = rewards or []\n",
    "    \n",
    "    def add_step(self, observation, action, reward):\n",
    "        self.observations.append(observation)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'trajectory: ' + str(list(zip(self.observations, self.actions)))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8452223-60e3-4395-8108-3f94b9302952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trajectory: [(312, 2), (312, 1), (212, 0), (312, 3), (312, 1), (212, 4), (212, 4), (212, 2), (232, 4), (232, 1), (132, 4), (132, 3), (112, 2), (132, 4), (132, 0), (232, 2), (252, 3), (232, 3), (212, 2), (232, 1), (132, 2), (132, 5), (132, 5), (132, 3), (112, 2), (132, 1), (32, 2), (32, 5), (32, 3), (12, 3), (12, 0), (112, 1), (12, 0), (112, 2), (132, 0), (232, 3), (212, 4), (212, 2), (232, 4), (232, 4), (232, 2), (252, 1), (152, 0), (252, 0), (352, 1), (252, 0), (352, 3), (332, 2), (352, 4), (352, 0), (452, 1), (352, 5), (352, 5), (352, 1), (252, 2), (272, 2), (292, 0), (392, 4), (392, 3), (372, 3), (372, 5), (372, 3), (372, 3), (372, 2), (392, 5), (392, 4), (392, 1), (292, 1), (192, 5), (192, 0), (292, 5), (292, 1), (192, 4), (192, 5), (192, 3), (172, 1), (72, 4), (72, 3), (52, 3), (52, 5), (52, 2), (72, 1), (72, 5), (72, 4), (72, 0), (172, 0), (272, 3), (252, 0), (352, 4), (352, 1), (252, 1), (152, 2), (172, 0), (272, 5), (272, 4), (272, 0), (372, 0), (472, 1), (372, 0), (472, 2), (492, 0), (492, 4), (492, 0), (492, 4), (492, 4), (492, 5), (492, 1), (392, 1), (292, 3), (272, 3), (252, 1), (152, 0), (252, 5), (252, 4), (252, 0), (352, 1), (252, 3), (232, 4), (232, 0), (332, 2), (352, 3), (332, 1), (232, 3), (212, 2), (232, 2), (252, 4), (252, 1), (152, 1), (52, 0), (152, 5), (152, 0), (252, 3), (232, 5), (232, 0), (332, 5), (332, 3), (332, 2), (352, 1), (252, 2), (272, 4), (272, 4), (272, 1), (172, 4), (172, 1), (72, 2), (92, 3), (72, 1), (72, 3), (52, 2), (72, 1), (72, 3), (52, 4), (52, 2), (72, 5), (72, 1), (72, 3), (52, 5), (52, 3), (52, 3), (52, 4), (52, 5), (52, 0), (152, 4), (152, 4), (152, 3), (152, 1), (52, 2), (72, 3), (52, 0), (152, 3), (152, 3), (152, 3), (152, 5), (152, 2), (172, 0), (272, 4), (272, 4), (272, 4), (272, 1), (172, 5), (172, 2), (192, 5), (192, 4), (192, 1), (92, 3), (72, 0), (172, 4), (172, 3), (152, 0), (252, 1), (152, 4), (152, 0), (252, 0), (352, 5), (352, 1), (252, 5), (252, 3), (232, 3), (212, 5), (212, 3), (212, 5), (212, 2), (232, 0), (332, 4), (332, 4), (332, 4), (332, 1), (232, 5), (232, 4), (232, 3), (212, 5), (212, 0), (312, 5), (312, 5), (312, 4), (312, 3), (312, 1), (212, 3), (212, 3), (212, 2), (232, 0), (332, 0), (432, 1), (332, 5), (332, 2), (352, 0), (452, 1), (352, 4), (352, 3), (332, 4), (332, 2), (352, 5), (352, 1), (252, 4), (252, 4), (252, 5), (252, 4), (252, 5), (252, 2), (272, 1), (172, 3), (152, 5), (152, 2), (172, 4), (172, 4), (172, 0), (272, 3), (252, 5), (252, 1), (152, 2), (172, 2), (192, 3), (172, 0), (272, 3), (252, 5), (252, 4), (252, 5), (252, 3), (232, 3), (212, 1), (112, 3), (112, 5), (112, 1), (12, 5), (12, 5), (12, 1), (12, 5), (12, 5), (12, 5), (12, 4), (12, 5), (12, 4), (12, 4), (12, 2), (32, 1), (32, 3), (12, 2), (32, 1), (32, 0), (132, 0), (232, 3), (212, 5), (212, 4), (212, 0), (312, 5), (312, 4), (312, 3), (312, 2), (312, 0), (412, 2), (412, 2), (412, 5), (412, 4), (412, 0), (412, 0), (412, 3), (412, 5), (412, 4), (412, 4), (412, 4), (412, 5), (412, 0), (412, 4), (412, 4), (412, 5), (412, 5), (412, 3), (412, 2), (412, 2), (412, 0), (412, 2), (412, 3), (412, 5), (412, 2), (412, 5), (412, 0), (412, 1), (312, 2), (312, 5), (312, 0), (412, 2), (412, 1), (312, 5), (312, 0), (412, 5), (412, 3), (412, 4), (412, 4), (412, 0), (412, 4), (412, 4), (412, 4), (412, 1), (312, 3), (312, 0), (412, 0), (412, 0), (412, 2), (412, 4), (412, 4), (412, 3), (412, 5), (412, 0), (412, 1), (312, 3), (312, 2), (312, 4), (312, 4), (312, 5), (312, 3), (312, 3), (312, 5), (312, 0), (412, 5), (412, 0), (412, 1), (312, 5), (312, 5), (312, 3), (312, 2), (312, 5), (312, 0), (412, 3), (412, 3), (412, 2), (412, 3), (412, 5), (412, 2), (412, 0), (412, 0), (412, 2), (412, 4), (412, 0), (412, 4), (412, 5), (412, 4), (412, 2), (412, 4), (412, 2), (412, 0), (412, 0), (412, 4), (412, 4), (412, 5), (412, 1), (312, 5), (312, 3), (312, 4), (312, 1), (212, 1), (112, 3), (112, 1), (12, 2), (32, 3), (12, 1), (12, 0), (112, 0), (212, 0), (312, 1), (212, 4), (212, 1), (112, 5), (112, 3), (112, 4), (112, 5), (112, 5), (112, 4), (112, 4), (112, 3), (112, 3), (112, 2), (132, 1), (32, 1), (32, 4), (32, 5), (32, 3), (12, 5), (12, 2), (32, 4), (32, 4), (32, 1), (32, 3), (12, 3), (12, 5), (12, 3), (12, 4), (12, 5), (12, 2), (32, 4), (32, 1), (32, 2), (32, 0), (132, 1), (32, 2), (32, 5), (32, 4), (32, 0), (132, 3), (112, 3), (112, 0), (212, 1), (112, 1), (12, 3), (12, 1), (12, 3), (12, 0), (112, 4), (112, 0), (212, 4), (212, 3), (212, 4), (212, 3), (212, 5), (212, 3), (212, 4), (212, 4), (212, 5), (212, 2), (232, 0), (332, 4), (332, 5), (332, 5), (332, 3), (332, 4), (332, 4), (332, 3), (332, 3), (332, 3), (332, 0), (432, 2), (452, 2), (452, 0), (452, 4), (452, 3), (432, 3), (432, 3), (432, 5), (432, 5), (432, 1), (332, 5), (332, 0), (432, 4), (432, 5), (432, 2), (452, 2), (452, 5), (452, 0), (452, 3), (432, 1), (332, 5), (332, 0), (432, 5), (432, 5), (432, 3), (432, 4), (432, 2), (452, 1), (352, 5), (352, 2), (352, 5), (352, 2), (352, 0), (452, 1), (352, 0), (452, 2), (452, 3), (432, 5), (432, 3), (432, 5), (432, 2), (452, 3), (432, 0), (432, 1), (332, 0), (432, 4), (432, 0), (432, 4), (432, 3), (432, 4), (432, 2), (452, 5), (452, 0), (452, 5), (452, 5), (452, 4), (452, 5), (452, 0), (452, 3), (432, 3), (432, 5), (432, 0), (432, 2), (452, 1), (352, 4), (352, 1), (252, 0), (352, 2), (352, 2), (352, 5), (352, 2), (352, 3), (332, 0), (432, 4), (432, 5), (432, 5), (432, 0), (432, 4), (432, 0), (432, 3), (432, 3), (432, 1), (332, 4), (332, 0), (432, 0), (432, 1), (332, 2), (352, 4), (352, 5), (352, 2), (352, 4), (352, 5), (352, 3), (332, 1), (232, 2), (252, 4), (252, 3), (232, 2), (252, 5), (252, 0), (352, 1), (252, 1), (152, 2), (172, 1), (72, 0), (172, 0), (272, 0), (372, 4), (372, 2), (392, 5), (392, 2), (392, 3), (372, 3), (372, 3), (372, 5), (372, 3), (372, 4), (372, 2), (392, 1), (292, 0), (392, 2), (392, 3), (372, 5), (372, 0), (472, 2), (492, 3), (472, 4), (476, 2), (496, 4), (496, 0), (496, 1), (396, 5), (396, 2), (396, 1), (296, 3), (276, 2), (296, 4), (296, 1), (196, 2), (196, 3), (176, 1), (76, 4), (76, 1), (76, 4), (76, 0), (176, 2), (196, 0), (296, 4), (296, 0), (396, 1), (296, 5), (296, 0), (396, 2), (396, 3), (376, 4), (376, 2), (396, 3), (376, 1), (276, 4), (276, 2), (296, 5), (296, 3), (276, 0), (376, 1), (276, 5), (276, 3), (256, 3), (236, 4), (236, 4), (236, 1), (136, 1), (36, 0), (136, 5), (136, 5), (136, 4), (136, 3), (116, 0), (216, 5), (216, 5), (216, 5), (216, 3), (216, 1), (116, 5), (116, 2), (136, 1), (36, 1), (36, 3), (16, 1), (16, 1), (16, 5)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_trajectory(policy, max_trajectory_length=float('inf')):\n",
    "    # init trajectory object\n",
    "    trajectory = Trajectory()\n",
    "    \n",
    "    # get first observation\n",
    "    obs = env.reset()\n",
    "    \n",
    "    # init first reward\n",
    "    reward = 0\n",
    "    # iterate and step in environment.\n",
    "    # limit num actions for incomplete policies\n",
    "    for i in itertools.count(start=1):\n",
    "        action = policy(obs)\n",
    "        old_obs = obs\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        trajectory.add_step(old_obs, action, reward)\n",
    "        \n",
    "        if done or i >= max_trajectory_length:\n",
    "            break\n",
    "    \n",
    "    return trajectory\n",
    "\n",
    "trajectory = get_trajectory(helicopter_policy)\n",
    "trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7dd953-07c5-4bcf-84eb-d209fae2defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(policy, num_trajectories, max_trajectory_length=float('inf')):\n",
    "    trajectories = []\n",
    "    for _ in range(num_trajectories):\n",
    "        trajectories.append(get_trajectory(policy, max_trajectory_length))\n",
    "\n",
    "    return trajectories\n",
    "\n",
    "# get the same trajectories every time!\n",
    "env.seed(seed)\n",
    "\n",
    "raw_data = collect_data(helicopter_policy, num_trajectories=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802378f8-f6da-421b-848e-2b565ce8c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def build_decision_dict(raw_data):\n",
    "    state_action_scores = defaultdict(lambda: defaultdict(lambda: []))\n",
    "    for trajectory in raw_data:\n",
    "        reward_sum = 0\n",
    "        for state, action, reward in reversed(list(zip(trajectory.observations, trajectory.actions, trajectory.rewards))):\n",
    "            reward_sum += reward\n",
    "            state_action_scores[state][action].append(reward_sum)\n",
    "            \n",
    "    for state, action_values in state_action_scores.items():\n",
    "        for action, values_list in action_values.items():\n",
    "            state_action_scores[state][action] = np.mean(values_list)\n",
    "        state_action_scores[state] = max(state_action_scores[state], key=state_action_scores[state].get)\n",
    "    return state_action_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d4dfa3-adac-4f0a-a0f7-b49ecef66c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCCPolicy:\n",
    "    def __init__(self, state_action_map):\n",
    "        self.state_action_map = state_action_map\n",
    "    \n",
    "    def __call__(self, obs):\n",
    "        # preprocess observation\n",
    "        return self.state_action_map[obs]\n",
    "\n",
    "# create a policy driven by the MLP model that uses the same preprocessing function as in\n",
    "# training\n",
    "policy = MCCPolicy(build_decision_dict(raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c684816-e314-4463-a610-6d743bf64313",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reward, mean_reward = evaluate_policy(env, helicopter_policy, num_episodes=10000, seed=seed)\n",
    "print('Monte Carlo Policy')\n",
    "print('---------')\n",
    "print(f'total reward over all episodes: {total_reward}')\n",
    "print(f'mean reward per episode:        {mean_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ffad55-a287-4eee-8e02-8b8547ced147",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reward, mean_reward = evaluate_policy(env, policy, num_episodes=10000, seed=seed)\n",
    "print('Monte Carlo Control Policy')\n",
    "print('-----------------')\n",
    "print(f'total reward over all episodes: {total_reward}')\n",
    "print(f'mean reward per episode:        {mean_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c1b91-6bf4-44b5-b4c8-eae595fd3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will run forever until it is interrupted\n",
    "# animate_policy(env, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af75b62-4f16-4908-9f68-5bb2cbde82c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
